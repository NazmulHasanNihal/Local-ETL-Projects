{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Log File Analysis ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import sqlite3\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_log_files(directory):\n",
    "    log_data = []\n",
    "    files = [file for file in os.listdir(directory) if file.endswith('.csv') or file.endswith('.tsv')]\n",
    "\n",
    "    for file in files:\n",
    "        with open(os.path.join(directory, file), 'r', newline='') as f:\n",
    "            if file.endswith('.csv'):\n",
    "                delimiter = ','\n",
    "            elif file.endswith('.tsv'):\n",
    "                delimiter = '\\t'\n",
    "            else:\n",
    "                continue  # Skip unsupported file types\n",
    "\n",
    "            reader = csv.reader(f, delimiter=delimiter)\n",
    "            next(reader)  # Skip header\n",
    "            for row in reader:\n",
    "                log_data.append(row)\n",
    "\n",
    "    return log_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(raw_data):\n",
    "    transformed_data = []\n",
    "    \n",
    "    for row in raw_data:\n",
    "        if len(row) < 5:\n",
    "            continue  # Skip rows that do not have enough fields\n",
    "        \n",
    "        try:\n",
    "            if row[1].strip():  # Check if timestamp field is not empty\n",
    "                timestamp = datetime.fromisoformat(row[1].strip())  # Assuming the timestamp is in ISO format\n",
    "            else:\n",
    "                continue  # Skip rows with empty timestamps\n",
    "        except ValueError:\n",
    "            continue  # Skip rows with invalid timestamps\n",
    "        \n",
    "        # Example transformation: Extracting relevant fields\n",
    "        transformed_row = {\n",
    "            'timestamp': timestamp,\n",
    "            'field1': row[2],\n",
    "            'field2': row[3],\n",
    "            'field3': row[4],\n",
    "            'field4': row[0] if len(row) > 5 else ''  # Example handling optional field\n",
    "        }\n",
    "        \n",
    "        transformed_data.append(transformed_row)\n",
    "    \n",
    "    return transformed_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_into_database(data, db_file):\n",
    "    conn = sqlite3.connect(db_file)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    # Create table if not exists\n",
    "    c.execute('''CREATE TABLE IF NOT EXISTS logs\n",
    "                 (id INTEGER PRIMARY KEY AUTOINCREMENT, timestamp TEXT, field1 TEXT, field2 TEXT, field3 TEXT, field4 TEXT)''')\n",
    "    \n",
    "    # Insert data into the table\n",
    "    for row in data:\n",
    "        c.execute(\"INSERT INTO logs (timestamp, field1, field2, field3, field4) VALUES (?, ?, ?, ?, ?)\",\n",
    "                  (row['timestamp'].isoformat(), row['field1'], row['field2'], row['field3'], row['field4']))\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETL process completed. Data loaded into logs.db.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Step 1: Extract data from log files (CSV and TSV) in a directory\n",
    "    directory = 'Logs_Data'  # Replace with your directory path\n",
    "    raw_data = extract_from_log_files(directory)\n",
    "\n",
    "    # Step 2: Transform data (renaming field names)\n",
    "    transformed_data = transform_data(raw_data)\n",
    "\n",
    "    # Step 3: Load data into SQLite database\n",
    "    db_file = 'logs.db'\n",
    "    load_into_database(transformed_data, db_file)\n",
    "\n",
    "    print(f\"ETL process completed. Data loaded into {db_file}.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
